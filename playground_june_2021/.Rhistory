getwd()
setwd("C:/Users/Owner")
install.packages('packrat')
setwd("C:/Users/Owner/Repos/Jake/kaggle_competitions/playground_june_2021")
packrat::init()
install.packages(tidymodels)
install.packages('tidymodels')
library(tidymodels)
library(tidyverse)
library(packrat)
library(tidymodels)
train_data <- read_csv('train.csv')
test_data <- read_csv('test.csv')
sample_submission <- read_csv('sample_submission.csv')
View(train_data)
View(test_data)
#### Split data ####
set.seed(911)
# Create random training, validation, and test sets
# Input 2. Set the fractions of the dataframe you want to split into
fraction_train <- 0.60
fraction_validation <- 0.20
fraction_test <- 0.20
# Compute sample sizes.
sample_size_train <- floor(fraction_train * nrow(competition_data))
competition_data <- read_csv('train.csv')
competition_test <- read_csv('test.csv')
sample_submission <- read_csv('sample_submission.csv')
#### Split data ####
set.seed(911)
# Create random training, validation, and test sets
# Input 2. Set the fractions of the dataframe you want to split into
fraction_train <- 0.60
fraction_validation <- 0.20
fraction_test <- 0.20
# Compute sample sizes.
sample_size_train <- floor(fraction_train * nrow(competition_data))
sample_size_validation <- floor(fraction_validation * nrow(competition_data))
sample_size_test <- floor(fraction_test * nrow(competition_data))
# Create the randomly-sampled indices for the dataframe. Use setdiff() to
# avoid overlapping subsets of indices.
indices_training <- sort(sample(seq_len(nrow(competition_data)), size=sample_size_train))
indices_not_training <- setdiff(seq_len(nrow(competition_data)), indices_training)
indices_validation <- sort(sample(indices_not_training, size=sample_size_validation))
indices_test <- setdiff(indices_not_training, indices_validation)
# Finally, output the three dataframes for training, validation and test.
train_data <- competition_data[indices_training, ]
validation_data <- competition_data[indices_validation, ]
test_data <- competition_data[indices_test, ]
model_recipe <-
recipe(target ~ ., data = train_data) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors()) %>%
#prep(training = train_data, retain = TRUE)
model_recipe <-
recipe(target ~ ., data = train_data) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors())
#prep(training = train_data, retain = TRUE)
#fit model
train_cv <- rsample::vfold_cv(train_data, v = 5)
model_specification <-
linear_reg(penalty = tune(),
mixture = 0.5) %>%
set_engine("glmnet")
model_workflow <- workflow() %>%
add_recipe(model_recipe) %>%
add_model(model_specification)
model_grid <- expand_grid(penalty = seq(0,10, by = 0.5))
model_tuned <- tune_grid(model_workflow,
resamples = train_cv, #cross-validation
grid = model_grid) #grid of tunable values
install.packages('glmnet')
#fit model
train_cv <- rsample::vfold_cv(train_data, v = 5)
model_specification <-
linear_reg(penalty = tune(),
mixture = 0.5) %>%
set_engine("glmnet")
model_workflow <- workflow() %>%
add_recipe(model_recipe) %>%
add_model(model_specification)
model_grid <- expand_grid(penalty = seq(0,10, by = 0.5))
model_tuned <- tune_grid(model_workflow,
resamples = train_cv, #cross-validation
grid = model_grid) #grid of tunable values
#fit model
train_cv <- rsample::vfold_cv(train_data, v = 5)
model_specification <-
linear_reg(penalty = tune(),
mixture = 0.5,
family = 'multinomial') %>%
set_engine("glmnet")
#fit model
train_cv <- rsample::vfold_cv(train_data, v = 5)
model_specification <-
multinom_reg(penalty = tune(),
mixture = 0.5) %>%
set_engine("glmnet")
model_workflow <- workflow() %>%
add_recipe(model_recipe) %>%
add_model(model_specification)
model_grid <- expand_grid(penalty = seq(0,10, by = 0.5))
model_tuned <- tune_grid(model_workflow,
resamples = train_cv, #cross-validation
grid = model_grid) #grid of tunable values
#preview the tuning curve for penalty
model_tuned %>% collect_metrics() %>%
ggplot(aes(penalty, mean, color = .metric)) +
geom_line(size = 1.5, show.legend = FALSE) +
facet_wrap(~.metric, scales = "free", nrow = 2)
#preview the tuning curve for penalty
model_tuned %>% collect_metrics() %>%
ggplot(aes(penalty, mean, color = .metric)) +
geom_line(size = 1.5, show.legend = FALSE) +
facet_wrap(~.metric, scales = "free", nrow = 2) +
theme_bw()
#preview the tuning curve for penalty
model_tuned %>% collect_metrics() %>%
ggplot(aes(penalty, mean, color = .metric)) +
geom_line(size = 1, show.legend = FALSE) +
geom_point(size = 0.5, show.legend = FALSE) +
facet_wrap(~.metric, scales = "free", nrow = 2) +
theme_bw()
#preview the tuning curve for penalty
model_tuned %>% collect_metrics() %>%
ggplot(aes(penalty, mean, color = .metric)) +
geom_line(size = 1, show.legend = FALSE) +
geom_point(size = 1.5, show.legend = FALSE) +
facet_wrap(~.metric, scales = "free", nrow = 2) +
theme_bw()
#select the penalty that yields the lowest rmse
bestPenalty <- model_tuned %>% select_best("rmse")
model_tuned$.metrics
?select_best
#select the penalty that yields the lowest rmse
bestPenalty <- model_tuned %>% select_best()
#finalize workflow using the best penalty
final <- finalize_workflow(model_workflow, bestPenalty)
final %>%
#fit on train data
fit(music_train) %>%
#pull the fit
pull_workflow_fit() %>%
#get variable importance and mutate it with the absolute value of importance.
#reorder variables by their absolute importance
vi() %>%
mutate(Importance = abs(Importance),
Variable = fct_reorder(Variable, Importance)) %>%
#plot
ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
geom_col()
final %>%
#fit on train data
fit(train_data) %>%
#pull the fit
pull_workflow_fit() %>%
#get variable importance and mutate it with the absolute value of importance.
#reorder variables by their absolute importance
vi() %>%
mutate(Importance = abs(Importance),
Variable = fct_reorder(Variable, Importance)) %>%
#plot
ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
geom_col()
final %>%
#fit on train data
fit(train_data) %>%
#pull the fit
pull_workflow_fit() %>%
#get variable importance and mutate it with the absolute value of importance.
#reorder variables by their absolute importance
#vi() %>%
mutate(Importance = abs(Importance),
Variable = fct_reorder(Variable, Importance)) %>%
#plot
ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
geom_col()
?vi()
#fit final model (from the final workflow) on the testing data and collect metrics
data <- last_fit(final,
split = music_split) %>%
collect_metrics()
#fit final model (from the final workflow) on the testing data and collect metrics
data <- last_fit(final,
split = test_data) %>%
collect_metrics()
?last_fit
?initial_split
#### Split data ####
set.seed(911)
# Create random training, validation, and test sets
data_split <- initial_split(competition_data, prop = 3/4)
train_data <- training(data_split)
test_data <- testing(competition_data)
test_data <- testing(data_split)
model_recipe <-
recipe(target ~ ., data = train_data) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors())
#prep(training = train_data, retain = TRUE)
#fit model
train_cv <- rsample::vfold_cv(train_data, v = 5)
model_specification <-
multinom_reg(penalty = tune(),
mixture = 0.5) %>%
set_engine("glmnet")
model_workflow <- workflow() %>%
add_recipe(model_recipe) %>%
add_model(model_specification)
model_grid <- expand_grid(penalty = seq(0,10, by = 0.5))
model_tuned <- tune_grid(model_workflow,
resamples = train_cv, #cross-validation
grid = model_grid) #grid of tunable values
#### Split data ####
set.seed(911)
# Create random training, validation, and test sets
train_split <- initial_split(competition_data, prop = 1/2)
train_data <- training(train_split)
validation_test_data <- testing(train_split)
validation_test_split <- initial_split(validation_test_data, prop = 1/2)
validation_data <- training(validation_test_split)
test_data <- testing(validation_test_split)
model_recipe <-
recipe(target ~ ., data = train_data) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors())
#prep(training = train_data, retain = TRUE)
#fit model
train_cv <- rsample::vfold_cv(train_data, v = 5)
model_specification <-
multinom_reg(penalty = tune(),
mixture = 0.5) %>%
set_engine("glmnet")
model_workflow <- workflow() %>%
add_recipe(model_recipe) %>%
add_model(model_specification)
model_grid <- expand_grid(penalty = seq(0,10, by = 0.5))
model_tuned <- tune_grid(model_workflow,
resamples = train_cv, #cross-validation
grid = model_grid) #grid of tunable values
#preview the tuning curve for penalty
model_tuned %>% collect_metrics() %>%
ggplot(aes(penalty, mean, color = .metric)) +
geom_line(size = 1, show.legend = FALSE) +
geom_point(size = 1.5, show.legend = FALSE) +
facet_wrap(~.metric, scales = "free", nrow = 2) +
theme_bw()
#select the penalty that yields the lowest rmse
bestPenalty <- model_tuned %>% select_best()
#finalize workflow using the best penalty
final <- finalize_workflow(model_workflow, bestPenalty)
#select the penalty that yields the lowest error
bestPenalty <- model_tuned %>% select_best('roc_auc')
#finalize workflow using the best penalty
final <- finalize_workflow(model_workflow, bestPenalty)
#fit final model (from the final workflow) on the testing data and collect metrics
data <- last_fit(final,
split = validation_data) %>%
collect_metrics()
#fit final model (from the final workflow) on the testing data and collect metrics
data <- last_fit(final, split = validation_data) %>%
collect_metrics()
#fit final model (from the final workflow) on the testing data and collect metrics
data <- last_fit(final, split = test_data) %>%
collect_metrics()
#fit final model (from the final workflow) on the testing data and collect metrics
data <- last_fit(final, split = validation_test_data) %>%
collect_metrics()
#fit final model (from the final workflow) on the testing data and collect metrics
data <- last_fit(final, split = train_split) %>%
collect_metrics()
View(data)
#fit final model (from the final workflow) on the testing data and collect metrics
final_fit <- last_fit(final, split = train_split)
final_fit %>%
collect_metrics()
final_fit %>%
collect_predictions() %>%
roc_curve(class, .pred_PS) %>%
autoplot()
final_fit %>%
collect_predictions()
final_fit %>%
collect_predictions()
final_fit %>%
collect_predictions() %>%
conf_mat(target, .pred_class) %>%
pluck(1) %>%
as_tibble() %>%
ggplot(aes(Prediction, Truth, alpha = n)) +
geom_tile(show.legend = FALSE) +
geom_text(aes(label = n), colour = "white", alpha = 1, size = 8)
#fit model
train_cv <- rsample::vfold_cv(train_data, v = 5)
model_specification <-
multinom_reg(penalty = tune(),
mixture = tune()) %>%
set_engine("glmnet")
model_workflow <- workflow() %>%
add_recipe(model_recipe) %>%
add_model(model_specification)
model_grid <- expand_grid(penalty = seq(0,10, by = 0.5))
model_tuned <- tune_grid(model_workflow,
resamples = train_cv, #cross-validation
grid = model_grid) #grid of tunable values
#fit model
train_cv <- rsample::vfold_cv(train_data, v = 5)
model_specification <-
multinom_reg(penalty = tune(),
mixture = tune()) %>%
set_engine("glmnet")
model_workflow <- workflow() %>%
add_recipe(model_recipe) %>%
add_model(model_specification)
model_grid <- expand_grid(penalty = seq(0,10, by = 0.5),
mixture = seq(0,10, by = 0.5))
model_tuned <- tune_grid(model_workflow,
resamples = train_cv, #cross-validation
grid = model_grid) #grid of tunable values
#fit model
train_cv <- rsample::vfold_cv(train_data, v = 5)
model_specification <-
multinom_reg(penalty = tune(),
mixture = tune()) %>%
set_engine("glmnet")
model_workflow <- workflow() %>%
add_recipe(model_recipe) %>%
add_model(model_specification)
model_grid <- expand_grid(penalty = seq(0,10, by = 0.5),
mixture = seq(0,1, by = 0.1))
model_tuned <- tune_grid(model_workflow,
resamples = train_cv, #cross-validation
grid = model_grid) #grid of tunable values
#preview the tuning curve for penalty
model_tuned %>% collect_metrics() %>%
ggplot(aes(penalty, mean, color = .metric)) +
geom_line(size = 1, show.legend = FALSE) +
geom_point(size = 1.5, show.legend = FALSE) +
facet_wrap(~.metric, scales = "free", nrow = 2) +
theme_bw()
#preview the tuning curve for mixture
model_tuned %>% collect_metrics() %>%
ggplot(aes(mixture, mean, color = .metric)) +
geom_line(size = 1, show.legend = FALSE) +
geom_point(size = 1.5, show.legend = FALSE) +
facet_wrap(~.metric, scales = "free", nrow = 2) +
theme_bw()
#select the penalty that yields the lowest error
bestPenalty <- model_tuned %>% select_best('roc_auc')
#finalize workflow using the best penalty
final <- finalize_workflow(model_workflow, bestPenalty)
#fit final model (from the final workflow) on the testing data and collect metrics
final_fit <- last_fit(final, split = train_split)
final_fit %>%
collect_metrics()
packrat::status()
packrat::restore()
packrate::snapshot()
packrat::snapshot()
packrat::status()
packrat::restore()
packrat::status()
packrat::restore()
packrat::status()
packrat::snapshot()
packrat::status()
packrat::restore()
setwd("C:/Users/Owner/Repos/Jake/kaggle_competitions/playground_june_2021")
packrat::restore()
install.packages('renv')
renv::migrate()
renv::status()
renv::snapshot()
renv::status()
revn::snapshot()
renv::snapshot()
renv::status()
